{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "~p.392 - Multi Layers, Optimizers.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "keB-8-amNu8Y",
        "outputId": "5ebec5e9-ed73-41e3-a26e-0d9a34f4d5b6"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-labels-idx1-ubyte.gz\n",
            "32768/29515 [=================================] - 0s 0us/step\n",
            "40960/29515 [=========================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/train-images-idx3-ubyte.gz\n",
            "26427392/26421880 [==============================] - 0s 0us/step\n",
            "26435584/26421880 [==============================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-labels-idx1-ubyte.gz\n",
            "16384/5148 [===============================================================================================] - 0s 0us/step\n",
            "Downloading data from https://storage.googleapis.com/tensorflow/tf-keras-datasets/t10k-images-idx3-ubyte.gz\n",
            "4423680/4422102 [==============================] - 0s 0us/step\n",
            "4431872/4422102 [==============================] - 0s 0us/step\n"
          ]
        }
      ],
      "source": [
        "# 심층 신경망\n",
        "# 인공 신경망에서 층을 더 많이 넣은게 심층 신경망이다.\n",
        "\n",
        "# 기본적인 베이스\n",
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "from sklearn.model_selection import cross_validate\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled = train_scaled.reshape(-1, 28*28)"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제 여기서 \"은닉층 100개의 뉴런\", 그리고 거기에 활성화 함수를 넣어보자.\n",
        "# 입력층과 출력층 사이에 있는 모든 층을 은닉층이라고 부른다.\n",
        "\n",
        "# 출력층에서 사용하는 활성화 함수는 이진인 경우, 다중인 경우에 쓰이는게 딱 나눠져 있어서\n",
        "# 제한이 되어있는데, 은닉층에서는 이게 비교적 자유롭다. 예를 들어 볼 렐루 함수라는걸 사용한다.\n",
        "\n",
        "# 참고로 회귀로 신경망 쓸거면 활성화 함수를 사용하지 않아도 된다.\n",
        "# 분류는, 확률을 출력하기 위해서 사용하는 것 이므로.\n",
        "\n",
        "# 그러면 왜 은닉층에도 활성화 함수가 필요할까?\n",
        "# 선형 방정식 두개를 생각해보자. 단순 선형 계산만으로 이루어져 있다면,\n",
        "# 변수 하나를 소거할 수 있게 된다. 즉, 의미가 없는 층이 된다는 것이다.\n",
        "# 그래서 첫 층에서 출력된 값을 적당히 비틀어 줄 필요가 있다.\n",
        " \n",
        "# 은닉층이 몇 개의 뉴런을 가져야 할지 판단하는건 경험이 필요하다. (적어도 출력층 뉴런보다는 많아야 한다.)\n",
        "dense1 = keras.layers.Dense(100, activation='sigmoid', input_shape=(784,))\n",
        "\n",
        "# 얘는 출력층이다.\n",
        "dense2 = keras.layers.Dense(10, activation='softmax')"
      ],
      "metadata": {
        "id": "XVbD3Af4PGVU"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 다음으로 심층 신경망을 연결해서 다 써서 만들어보자.\n",
        "model = keras.Sequential([dense1, dense2])\n",
        "model.summary()\n",
        "\n",
        "# 그렇다면 두번째 층의 모델 파라미터의 총 개수는? -> 1,010개이다. 100(은닉층) * 10(출력층) + 10(출력층마다 있는 절편)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LpdiS4S0ReAe",
        "outputId": "53db7886-b1b3-4797-801d-4fea9f82516a"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_1\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense (Dense)               (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_1 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# keras.Sequential에 층을 추가하는 다른 방법.\n",
        "model = keras.Sequential([\n",
        "                          keras.layers.Dense(100, activation='sigmoid', input_shape=(784,),\n",
        "                                             name='hidden'),\n",
        "                          keras.layers.Dense(10,activation='softmax',name='output')\n",
        "],name='패션 MNIST 모델')\n",
        "\n",
        "# 이렇게 하면 층들을 한 눈에 보기도 쉽고 이름까지 지정할 수 있다. 층 이름은 반드시 영문!!\n",
        "model.summary()\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LW5UkK3ITqpp",
        "outputId": "39868910-15e6-48bb-f665-4e6f2428b1b4"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"패션 MNIST 모델\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " hidden (Dense)              (None, 100)               78500     \n",
            "                                                                 \n",
            " output (Dense)              (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 또 다른 방법\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Dense(100, activation='sigmoid', input_shape=(784,)))\n",
        "model.add(keras.layers.Dense(10,activation='softmax'))\n",
        "model.summary()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TA1DOIMbUUMv",
        "outputId": "dedb0451-cb07-4f18-85b6-9e83c63dc405"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_2\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " dense_2 (Dense)             (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_3 (Dense)             (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제 훈련해보자.\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YFtqNTqeUpmX",
        "outputId": "42c1d26f-04f4-419c-9db8-0e758efe2c44"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1875/1875 [==============================] - 6s 3ms/step - loss: 0.5346 - accuracy: 0.8151\n",
            "Epoch 2/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3923 - accuracy: 0.8572\n",
            "Epoch 3/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3607 - accuracy: 0.8698\n",
            "Epoch 4/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3394 - accuracy: 0.8768\n",
            "Epoch 5/5\n",
            "1875/1875 [==============================] - 5s 3ms/step - loss: 0.3235 - accuracy: 0.8825\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa17db53b90>"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 렐루 함수"
      ],
      "metadata": {
        "id": "UiSBqpD5VXKQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 렐루 함수\n",
        "# max(0,z)이다. 음수로 가는건 그냥 0으로 만들어 버린다.\n",
        "# 이미지 처리에서 아주 좋은 성능을 낼 수 있다.\n",
        "\n",
        "# 그 전에 지금까지 reshape 써서 1차원으로 펼쳤던거 말고 \n",
        "# 케라스에서 제공하는 Flatten 층을 공부해보자.\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28))) # 여기서 일자로 펴줬다!\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "\n",
        "model.summary()\n",
        "# 그렇다고 Flatten 층을 학습 층의 개수에 추가해주진 않는다.\n",
        "# 그러나 summary()에서 기존의 차원을 엿볼 수 있다.\n",
        "# 전처리까지 모델에 넣어보자 하는게 케라스의 철학이다.\n",
        "\n",
        "(train_input, train_target), (test_input, test_target) = keras.datasets.fashion_mnist.load_data()\n",
        "train_scaled = train_input / 255.0\n",
        "train_scaled, val_scaled, train_target, val_target = train_test_split(train_scaled, train_target, test_size=0.2, random_state=42)\n",
        "model.compile(loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "cs3BKSudVV76",
        "outputId": "1abb8d22-f550-4af9-b4bc-1058fb137534"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model: \"sequential_8\"\n",
            "_________________________________________________________________\n",
            " Layer (type)                Output Shape              Param #   \n",
            "=================================================================\n",
            " flatten_5 (Flatten)         (None, 784)               0         \n",
            "                                                                 \n",
            " dense_14 (Dense)            (None, 100)               78500     \n",
            "                                                                 \n",
            " dense_15 (Dense)            (None, 10)                1010      \n",
            "                                                                 \n",
            "=================================================================\n",
            "Total params: 79,510\n",
            "Trainable params: 79,510\n",
            "Non-trainable params: 0\n",
            "_________________________________________________________________\n",
            "Epoch 1/10\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.5270 - accuracy: 0.8152\n",
            "Epoch 2/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3894 - accuracy: 0.8597\n",
            "Epoch 3/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3543 - accuracy: 0.8730\n",
            "Epoch 4/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3320 - accuracy: 0.8795\n",
            "Epoch 5/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3170 - accuracy: 0.8849\n",
            "Epoch 6/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.3071 - accuracy: 0.8911\n",
            "Epoch 7/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2969 - accuracy: 0.8953\n",
            "Epoch 8/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2892 - accuracy: 0.8983\n",
            "Epoch 9/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2835 - accuracy: 0.9003\n",
            "Epoch 10/10\n",
            "1500/1500 [==============================] - 4s 3ms/step - loss: 0.2747 - accuracy: 0.9043\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa17da10e10>"
            ]
          },
          "metadata": {},
          "execution_count": 16
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 이제 최종 점수는!\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KdmESB1pXTZy",
        "outputId": "396b6fbd-24e3-468d-d4eb-be9f3afc4cb6"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 2s 3ms/step - loss: 0.4003 - accuracy: 0.8775\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.4002610743045807, 0.8774999976158142]"
            ]
          },
          "metadata": {},
          "execution_count": 17
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 옵티마이저\n",
        "* 지금까지는 하이퍼파라미터를 잘 다뤘는데 이제 나옴.\n",
        "----\n",
        "추가할 은닉층의 개수  \n",
        "뉴런 개수  \n",
        "활성화 함수  \n",
        "층의 종류  \n",
        "배치 사이즈 매개변수  \n",
        "에포크 매개변수  \n"
      ],
      "metadata": {
        "id": "XwC0nh32XdfR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# 케라스는 기본적으로 미니배치 경사 하강법을 사용한다.\n",
        "# 미니배치 개수는 기본적으로 32개다.\n",
        "\n",
        "# 옵티마이저 - 케라스는 다양한 종류의 경사 하강법 알고리즘을 제공\n",
        "sgd = keras.optimizers.SGD(learning_rate=0.1) # 이거 'sgd'로 넣는거랑 똑같다. 학습률도 조정할 수 있다.\n",
        "model.compile(optimizer=sgd, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "\n",
        "# 기본 경사 하강법 옵티마이저는 모두 SGD 클래스에서 제공하는데, 해당 클래스의 momentum 매개변수의 기본값은 0이다.\n",
        "# 이를 0보다 큰 값으로 지정하면 마치 이전의 그레이던트를 가속도처럼 사용하는 모멘텀 최적화를 사용한다.\n",
        "# 보통 0.9 이상으로 지정한다.\n",
        "\n",
        "# 아래처럼 네스테로프 모멘텀 최적화를 키면 모멘텀 최적화를 2번 반복하여 구현하는데, 대부분 이게 기본보다 좋다.\n",
        "sgd = keras.optimizers.SGD(momentum=0.9, nesterov=True)"
      ],
      "metadata": {
        "id": "rRjTJo58Xouy"
      },
      "execution_count": 19,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# 모델이 최적점에 가까이 갈수록 학습률을 낮추는 것을 '적응적 학습률'이라고 한다.\n",
        "# Adagrad, RMSprop이 있는데, optimizer 매개변수의 기본값이 rmsprop이다.\n",
        "'''\n",
        "adagrad = keras.optimizers.Adagrad()\n",
        "model.compile(optimizer=adagrad, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "'''\n",
        "\n",
        "'''\n",
        "rmsprop = keras.optimizers.RMSprop()\n",
        "model.compile(optimizer=rmsprop, loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "'''\n",
        "\n",
        "model = keras.Sequential()\n",
        "model.add(keras.layers.Flatten(input_shape=(28,28))) # 여기서 일자로 펴줬다!\n",
        "model.add(keras.layers.Dense(100, activation='relu'))\n",
        "model.add(keras.layers.Dense(10, activation='softmax'))\n",
        "model.compile(optimizer='adam', loss='sparse_categorical_crossentropy', metrics='accuracy')\n",
        "model.fit(train_scaled, train_target, epochs=5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3i0Sk9XHcHe0",
        "outputId": "36ce6798-4f90-468f-cced-ffc4001096a8"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1/5\n",
            "1500/1500 [==============================] - 4s 2ms/step - loss: 0.5232 - accuracy: 0.8173\n",
            "Epoch 2/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3897 - accuracy: 0.8587\n",
            "Epoch 3/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3486 - accuracy: 0.8731\n",
            "Epoch 4/5\n",
            "1500/1500 [==============================] - 3s 2ms/step - loss: 0.3259 - accuracy: 0.8813\n",
            "Epoch 5/5\n",
            "1500/1500 [==============================] - 5s 3ms/step - loss: 0.3060 - accuracy: 0.8885\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "<keras.callbacks.History at 0x7fa17d657090>"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# 아담을 사용한 최종 결과\n",
        "model.evaluate(val_scaled, val_target)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Hg68wKLAdIV7",
        "outputId": "9261a066-9b30-45b2-da68-c600289e019f"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "375/375 [==============================] - 1s 2ms/step - loss: 0.3588 - accuracy: 0.8705\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[0.3588126599788666, 0.8705000281333923]"
            ]
          },
          "metadata": {},
          "execution_count": 21
        }
      ]
    }
  ]
}